<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AutonomOS Architecture</title>
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            border-bottom: 2px solid #333;
            padding-bottom: 10px;
        }
        h2 {
            margin-top: 40px;
            padding-bottom: 8px;
            border-bottom: 1px solid #ddd;
        }
        nav {
            background: #f5f5f5;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }
        nav ul {
            list-style: none;
            padding: 0;
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }
        nav a {
            text-decoration: none;
            padding: 8px 15px;
            background: #007bff;
            color: white;
            border-radius: 4px;
        }
        nav a:hover {
            background: #0056b3;
        }
        .mermaid {
            background: #fafafa;
            padding: 20px;
            margin: 20px 0;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .note {
            background: #e7f3ff;
            border-left: 4px solid #007bff;
            padding: 15px;
            margin: 20px 0;
        }
        .connector-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        .connector-card {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            border: 1px solid #dee2e6;
        }
        .connector-card h4 {
            margin-top: 0;
            color: #007bff;
        }
        @media (max-width: 768px) {
            nav ul {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <h1>AutonomOS Platform Architecture</h1>
    <p><strong>Multi-Tenant AI Orchestration Platform</strong> - Production-ready with 4 operational connectors</p>

    <nav>
        <h3>Quick Navigation</h3>
        <ul>
            <li><a href="#functional">Functional Overview</a></li>
            <li><a href="#aoa">Systems Overview</a></li>
            <li><a href="#overview">High-Level Architecture</a></li>
            <li><a href="#dataflow">Data Flow</a></li>
            <li><a href="#aam">AAM Components</a></li>
            <li><a href="#middleware">Middleware Stack</a></li>
            <li><a href="#database">Database Schema</a></li>
            <li><a href="#migrations">Database Migrations</a></li>
            <li><a href="#frontend">Frontend Architecture</a></li>
        </ul>
    </nav>

    <div class="note">
        <strong>Current Production Status (November 2025):</strong> Platform includes 4 operational connectors (Salesforce, FileSource, Supabase, MongoDB), complete drift detection, autonomous auto-repair, canonical event normalization, and Live Flow visualization. FileSource ‚Üí AAM ‚Üí DCL integration complete with AWS cost data routing to FinOps Pilot via heuristic domain filtering. <strong>Alembic migration system implemented</strong> for production-ready database schema versioning with automatic migrations on startup.
    </div>

    <section id="functional">
        <h2>Functional Overview</h2>
        <p><strong>What AutonomOS Does:</strong> Enterprise-grade agentic orchestration platform that unifies fragmented data sources, provides AI agents with real-time intelligence, and enables autonomous execution at scale with human oversight.</p>
        
        <pre class="mermaid">
flowchart TB
    DS["üìä DATA SOURCES<br/><br/><b>Function:</b> Provide raw business data<br/><br/><b>What they do:</b><br/>‚Ä¢ Salesforce stores CRM data<br/>‚Ä¢ Supabase tracks product usage<br/>‚Ä¢ MongoDB logs customer events<br/>‚Ä¢ CSV files hold legacy data<br/><br/><b>Problem:</b> Different formats,<br/>field names, structures"]
    
    AAM["üîß ADAPTIVE API MESH<br/><br/><b>Function:</b> Normalize chaos into order<br/><br/><b>What it does:</b><br/>‚Ä¢ Connects to each source<br/>‚Ä¢ Transforms to standard format<br/>‚Ä¢ Detects schema changes<br/>‚Ä¢ Auto-repairs broken mappings<br/>‚Ä¢ Uses AI to match similar fields<br/><br/><b>Output:</b> Clean, validated,<br/>canonical events"]
    
    DCL["üìö DATA CONNECTION LAYER<br/><br/><b>Function:</b> Create unified queryable views<br/><br/><b>What it does:</b><br/>‚Ä¢ Stores canonical events<br/>‚Ä¢ Builds materialized tables<br/>‚Ä¢ Links related records<br/>‚Ä¢ Infers relationships<br/>‚Ä¢ Provides SQL-like queries<br/><br/><b>Output:</b> Single source of truth<br/>for all business entities"]
    
    AGENTS["ü§ñ AI AGENTS<br/><br/><b>Function:</b> Take intelligent action<br/><br/><b>What they do:</b><br/>‚Ä¢ RevOps: Score deals, predict revenue<br/>‚Ä¢ FinOps: Find cost anomalies<br/>‚Ä¢ Query unified data (no ETL)<br/>‚Ä¢ Execute actions automatically<br/>‚Ä¢ Write back to sources<br/><br/><b>Result:</b> Automated insights<br/>and actions"]
    
    HITL["üì¢ HITL ALERTS<br/><br/><b>Function:</b> Human-in-the-loop notifications<br/><br/><b>Channels:</b><br/>‚Ä¢ Slack<br/>‚Ä¢ Email<br/>‚Ä¢ SMS<br/>‚Ä¢ Webhooks<br/><br/><b>Use cases:</b><br/>‚Ä¢ High-confidence alerts<br/>‚Ä¢ Manual review required<br/>‚Ä¢ Anomaly detection"]
    
    DS -->|"Raw events<br/>(messy, inconsistent)"| AAM
    AAM -->|"Canonical events<br/>(clean, validated)"| DCL
    DCL -->|"Unified data<br/>(queryable, linked)"| AGENTS
    AGENTS -->|"Insight-to-Action Loop<br/>(update, alert, optimize)"| AAM
    AAM -->|"Insight-to-Action Loop<br/>(Autonomous execution)"| DS
    AGENTS -->|"Critical alerts<br/>(human oversight)"| HITL
        </pre>
        
        <div class="note">
            <h4 style="margin-top: 0;">Key Functional Benefits</h4>
            <ol>
                <li><strong>Data Sources</strong> ‚Üí No integration work needed. Connect once, data flows automatically.</li>
                <li><strong>AAM</strong> ‚Üí Self-healing. When Salesforce adds a field, AAM detects and adapts automatically.</li>
                <li><strong>DCL</strong> ‚Üí Query all sources as one. No more writing separate queries for each system.</li>
                <li><strong>Agents</strong> ‚Üí Built on unified data. Write logic once, works across all sources.</li>
            </ol>
            
            <h4>Example Flow:</h4>
            <p>Salesforce emits "Opportunity closed" ‚Üí AAM normalizes to CanonicalOpportunity ‚Üí DCL materializes in unified view ‚Üí RevOps agent calculates pipeline health ‚Üí Agent updates forecast in Salesforce</p>
        </div>
    </section>

    <section id="aoa">
        <h2>Systems Overview: Agentic Orchestration Architecture</h2>
        <p>Complete data flow from external sources through intelligent normalization layers to domain agents.</p>
        <pre class="mermaid">
flowchart TB
  subgraph Sources["Data Sources Layer"]
    SF["Salesforce<br/>CRM Data"]
    SB["Supabase<br/>Product Analytics"]
    MG["MongoDB<br/>Customer Events"]
    FS["FileSource<br/>CSV/Legacy"]
  end

  subgraph AAM["Adaptive API Mesh - Intelligence Layer"]
    CONN["Connectors<br/>Extract & Normalize"]
    INTEL["AAM Intelligence<br/>Drift Detection, Auto-Repair, RAG"]
  end

  subgraph DCL["Data Connection Layer - Unified Ontology"]
    CANON["Canonical Event Store<br/>PostgreSQL"]
    MAT["Materialized Views<br/>DuckDB"]
  end

  subgraph Gateway["API Gateway"]
    READ["Read API<br/>JWT Auth"]
    WRITE["Write API<br/>Audit Logs"]
  end

  subgraph Agents["Domain Agents"]
    REVOPS["RevOps Pilot"]
    FINOPS["FinOps Pilot"]
  end

  SF & SB & MG & FS --> CONN
  CONN --> INTEL
  INTEL --> CANON
  CANON --> MAT
  MAT --> READ
  READ --> REVOPS & FINOPS
  REVOPS & FINOPS --> WRITE
  WRITE --> INTEL
        </pre>
        
        <div class="connector-list">
            <div class="connector-card">
                <h4>‚úÖ Salesforce</h4>
                <p>CRM data - Accounts, Opportunities, Contacts</p>
            </div>
            <div class="connector-card">
                <h4>‚úÖ Supabase</h4>
                <p>Product analytics - Usage metrics, health scores</p>
            </div>
            <div class="connector-card">
                <h4>‚úÖ MongoDB</h4>
                <p>Customer events - NoSQL event logs</p>
            </div>
            <div class="connector-card">
                <h4>‚úÖ FileSource</h4>
                <p>AWS cost data - CSV files (aws_resources, cost_reports) ‚Üí FinOps Pilot via heuristic filtering</p>
            </div>
        </div>
    </section>

    <section id="overview">
        <h2>High-Level System Architecture</h2>
        <p>Complete view of AutonomOS platform components and data flow.</p>
        <pre class="mermaid">
graph TB
    subgraph "Data Sources"
        SF[Salesforce]
        SB[Supabase]
        MG[MongoDB]
        FS[FileSource/CSV]
    end

    subgraph "AutonomOS Platform"
        subgraph "Frontend"
            UI[React UI]
            DCL_VIZ[DCL Graph]
            AAM_MON[AAM Monitor]
            LIVE[Live Flow]
        end

        subgraph "API Gateway"
            MW[Middleware Stack<br/>Auth, Rate Limit, Audit]
        end

        subgraph "Backend"
            API[FastAPI Server]
            DCL[DCL Engine]
            AAM[AAM Orchestrator]
            WORKER[RQ Worker]
        end

        subgraph "Data Layer"
            PG[(PostgreSQL)]
            REDIS[(Redis)]
            DUCK[(DuckDB)]
        end

        subgraph "AI"
            GEMINI[Gemini]
            RAG[RAG Engine]
        end
    end

    SF & SB & MG & FS --> AAM
    UI & DCL_VIZ & AAM_MON & LIVE --> MW
    MW --> API
    API --> DCL & AAM & WORKER
    AAM --> PG & GEMINI & RAG
    DCL --> DUCK
    WORKER --> REDIS
        </pre>
    </section>

    <section id="dataflow">
        <h2>Data Flow: Source ‚Üí AAM ‚Üí DCL</h2>
        <p>End-to-end journey of data from external sources through AAM to materialized DCL views.</p>
        <pre class="mermaid">
graph LR
    subgraph "Sources"
        SF_OPP[Salesforce<br/>Opportunity]
        SB_ACC[Supabase<br/>Account]
        MG_USG[MongoDB<br/>Usage]
        FS_CSV[FileSource<br/>CSV]
    end

    subgraph "AAM"
        CONN[Connectors]
        MAP[Mapping Registry]
        CANON[Canonical Schema]
        STREAM[Streams DB]
    end

    subgraph "DCL"
        SUB[Subscriber]
        MAT[Materialized Tables]
        API[Views API]
    end

    subgraph "Frontend"
        UI[React UI]
    end

    SF_OPP & SB_ACC & MG_USG & FS_CSV --> CONN
    CONN --> MAP
    MAP --> CANON
    CANON --> STREAM
    STREAM --> SUB
    SUB --> MAT
    MAT --> API
    API --> UI
        </pre>
    </section>

    <section id="aam">
        <h2>AAM (Adaptive API Mesh) Components</h2>
        <p>Three-plane architecture: Intelligence, Execution, and Control planes for self-healing data connectivity.</p>
        <pre class="mermaid">
graph TB
    subgraph "Intelligence Plane"
        ORCH[Orchestrator]
        DRIFT[Drift Repair Agent]
        SCHEMA[Schema Observer]
        RAG[RAG Engine]
    end

    subgraph "Execution Plane"
        SF_CONN[Salesforce Connector]
        SB_CONN[Supabase Connector]
        MG_CONN[MongoDB Connector]
        FS_CONN[FileSource Connector]
    end

    subgraph "Control Plane"
        MAP_REG[Mapping Registry<br/>YAML]
        CANON_SCH[Canonical Schemas<br/>Pydantic]
        CONN_REG[Connector Registry<br/>PostgreSQL]
    end

    SF_CONN & SB_CONN & MG_CONN & FS_CONN --> MAP_REG
    MAP_REG --> CANON_SCH
    ORCH --> DRIFT & SCHEMA & RAG
    DRIFT & SCHEMA --> CONN_REG
        </pre>
        
        <div class="note">
            <h4 style="margin-top: 0;">Intelligence Layer: LLM/RAG Behavior</h4>
            <p><strong>Key Insight:</strong> The LLM/RAG intelligence layer operates <em>identically</em> in both AAM mode and Legacy mode. Behavior is controlled by the <code>dev_mode</code> flag, not the data source type.</p>
            
            <h4>RAG Retrieval (Always Runs):</h4>
            <ul>
                <li>Queries Pinecone vector database for similar field mappings</li>
                <li>Executes in parallel for all fields using async tasks</li>
                <li>Caches results to avoid duplicate lookups</li>
                <li>Works identically whether using AAM connectors or legacy file sources</li>
            </ul>
            
            <h4>LLM Calls (Controlled by dev_mode):</h4>
            <ul>
                <li><strong>Dev Mode ON</strong> (dev_mode=true):
                    <ul>
                        <li>RAG runs ‚Üí Intelligent coverage check ‚Üí LLM called if needed</li>
                        <li>If RAG coverage >90%: Skip LLM, use RAG inventory</li>
                        <li>If RAG coverage 75-90%: LLM call with RAG context</li>
                        <li>If RAG coverage <75%: Full LLM reasoning</li>
                    </ul>
                </li>
                <li><strong>Prod Mode</strong> (dev_mode=false - DEFAULT):
                    <ul>
                        <li>RAG runs ‚Üí LLM skipped ‚Üí Heuristics used</li>
                        <li>Uses hard-coded domain rules for routing</li>
                        <li>Fast, deterministic, cost-effective</li>
                    </ul>
                </li>
            </ul>
            
            <h4>Domain Filtering (Heuristic Routing):</h4>
            <ul>
                <li><strong>FinOps Sources:</strong> snowflake, sap, netsuite, legacy_sql, <strong>filesource</strong> ‚Üí Route to FinOps Pilot</li>
                <li><strong>RevOps Sources:</strong> dynamics, salesforce, hubspot ‚Üí Route to RevOps Pilot</li>
                <li><strong>FinOps Entities:</strong> aws_resources, cost_reports</li>
                <li><strong>RevOps Entities:</strong> account, opportunity</li>
                <li><strong>Unknown Sources:</strong> Pass through without filtering for extensibility</li>
            </ul>
        </div>
    </section>

    <section id="middleware">
        <h2>Gateway Middleware Stack</h2>
        <p>Five-layer middleware stack with request flow and routing logic.</p>
        <pre class="mermaid">
graph TD
    REQ[HTTP Request]
    
    REQ --> MW1[1. Tracing<br/>trace_id]
    MW1 --> MW2[2. Auth<br/>JWT, tenant]
    MW2 --> MW3[3. Rate Limit<br/>Per-tenant]
    MW3 --> MW4[4. Idempotency]
    MW4 --> MW5[5. Audit Log]
    
    MW5 --> ROUTE{Route}
    
    ROUTE -->|/api/v1/auth| AUTH[Auth]
    ROUTE -->|/api/v1/aoa| AOA[AOA]
    ROUTE -->|/api/v1/aam| AAM[AAM]
    ROUTE -->|/api/v1/dcl| DCL[DCL]
    ROUTE -->|/dcl| DCL_WS[DCL WebSocket]
    ROUTE -->|/live-flow| LIVE[Live Flow]
    ROUTE -->|/| STATIC[Frontend]
        </pre>
    </section>

    <section id="database">
        <h2>Database Schema</h2>
        <p>PostgreSQL database schema with multi-tenant tables and relationships.</p>
        <pre class="mermaid">
erDiagram
    USERS ||--o{ CANONICAL_STREAMS : creates
    USERS {
        int id PK
        string username
        string email
        string hashed_password
        string tenant_id
    }

    CANONICAL_STREAMS ||--o{ MATERIALIZED_ACCOUNTS : sources
    CANONICAL_STREAMS ||--o{ MATERIALIZED_OPPORTUNITIES : sources
    CANONICAL_STREAMS {
        int id PK
        string tenant_id
        string entity
        jsonb data
        jsonb meta
        jsonb source
        datetime emitted_at
    }

    MATERIALIZED_ACCOUNTS {
        int id PK
        string tenant_id
        string account_id UK
        string name
        string industry
        decimal annual_revenue
        jsonb extras
        datetime created_at
    }

    MATERIALIZED_OPPORTUNITIES {
        int id PK
        string tenant_id
        string opportunity_id UK
        string account_id FK
        string name
        string stage
        decimal amount
        date close_date
        jsonb extras
        datetime created_at
    }
        </pre>
    </section>

    <section id="migrations">
        <h2>Database Migrations</h2>
        <p>Production-ready schema versioning with Alembic for safe, trackable changes.</p>
        
        <div class="note">
            <h4 style="margin-top: 0;">Key Features</h4>
            <ul>
                <li><strong>Automatic migrations on startup</strong> - Every server start runs <code>alembic upgrade head</code></li>
                <li><strong>Multi-Base architecture</strong> - Tracks both <code>app.models.Base</code> and <code>aam_hybrid.shared.models.Base</code> in one history</li>
                <li><strong>Baseline migration</strong> - Safe production deployment with existing data (no DROP TABLE warnings)</li>
                <li><strong>Version controlled</strong> - All migrations committed to git with code changes</li>
            </ul>
        </div>

        <pre class="mermaid">
flowchart LR
    DEV["üë®‚Äçüíª Developer<br/><br/>Modify models in:<br/>‚Ä¢ app/models.py<br/>‚Ä¢ aam_hybrid/shared/models.py"]
    
    GEN["üìù Generate Migration<br/><br/>alembic revision<br/>--autogenerate<br/>-m 'description'"]
    
    REVIEW["üîç Review<br/><br/>Check generated<br/>migration in<br/>alembic/versions/"]
    
    TEST["üß™ Test Locally<br/><br/>alembic upgrade head<br/><br/>Verify schema<br/>changes work"]
    
    COMMIT["‚úÖ Commit to Git<br/><br/>Migration script<br/>+ model changes"]
    
    DEPLOY["üöÄ Deploy<br/><br/>start.sh runs<br/>alembic upgrade head<br/>automatically"]
    
    PROD["üéØ Production<br/><br/>Schema updated<br/>Zero downtime<br/>Rollback-ready"]
    
    DEV --> GEN
    GEN --> REVIEW
    REVIEW --> TEST
    TEST --> COMMIT
    COMMIT --> DEPLOY
    DEPLOY --> PROD
        </pre>

        <div class="connector-list">
            <div class="connector-card">
                <h4>üì¶ Migration Commands</h4>
                <code style="display: block; margin: 5px 0;">alembic revision --autogenerate -m "msg"</code>
                <p>Generate new migration from model changes</p>
            </div>
            <div class="connector-card">
                <h4>‚¨ÜÔ∏è Apply Migrations</h4>
                <code style="display: block; margin: 5px 0;">alembic upgrade head</code>
                <p>Apply all pending migrations (auto-runs on startup)</p>
            </div>
            <div class="connector-card">
                <h4>‚¨áÔ∏è Rollback</h4>
                <code style="display: block; margin: 5px 0;">alembic downgrade -1</code>
                <p>Revert last migration</p>
            </div>
            <div class="connector-card">
                <h4>üìä Status</h4>
                <code style="display: block; margin: 5px 0;">alembic current</code>
                <p>Check current migration version</p>
            </div>
        </div>

        <div class="note">
            <h4 style="margin-top: 0;">First-Time Production Setup</h4>
            <p><strong>IMPORTANT:</strong> Before deploying Alembic to an existing production database, run the baseline stamp script:</p>
            <code style="display: block; background: #2d2d2d; color: #f8f8f2; padding: 10px; border-radius: 4px; margin: 10px 0;">./scripts/stamp_baseline.sh</code>
            <p>This marks the current production schema as baseline, preventing destructive DROP TABLE operations during first migration.</p>
        </div>
    </section>

    <section id="frontend">
        <h2>Frontend Architecture</h2>
        <p>React/TypeScript frontend with real-time WebSocket updates and 5 pages.</p>
        <pre class="mermaid">
graph TB
    subgraph "Pages"
        HOME[Home<br/>Hero + FAQ]
        DCL_PAGE[DCL Graph<br/>Sankey Viz]
        AAM_PAGE[AAM Monitor<br/>Intelligence Metrics]
        ONT_PAGE[Ontology<br/>Mappings]
        LIVE_PAGE[Live Flow<br/>Real-time Events]
    end

    subgraph "Components"
        SANKEY[Sankey Graph<br/>D3.js]
        METRICS[Metrics Cards]
        EVENT_PILLS[Event Pills<br/>Animated]
    end

    subgraph "Real-time"
        WS[DCL WebSocket]
        MOCK[Mock Generator]
    end

    HOME --> DCL_PAGE & AAM_PAGE & ONT_PAGE & LIVE_PAGE
    DCL_PAGE --> SANKEY
    AAM_PAGE --> METRICS
    LIVE_PAGE --> EVENT_PILLS
    DCL_PAGE --> WS
    LIVE_PAGE --> MOCK
        </pre>
        
        <div class="note">
            <strong>Frontend Pages:</strong>
            <ul>
                <li><strong>Home</strong> - Hero section with value proposition + FAQ</li>
                <li><strong>DCL Graph</strong> - Interactive Sankey visualization of data flow</li>
                <li><strong>AAM Monitor</strong> - Intelligence metrics and connection health</li>
                <li><strong>Ontology</strong> - Data mappings and universe view</li>
                <li><strong>Live Flow</strong> - Real-time event visualization with animated pills (NEW)</li>
            </ul>
        </div>
    </section>

    <footer style="margin-top: 60px; padding-top: 20px; border-top: 1px solid #ddd; text-align: center; color: #666;">
        <p><strong>AutonomOS Platform</strong> - Multi-Tenant AI Orchestration Architecture</p>
        <p>Technology Stack: React, TypeScript, FastAPI, PostgreSQL, DuckDB, Redis, Gemini AI</p>
    </footer>
</body>
</html>
